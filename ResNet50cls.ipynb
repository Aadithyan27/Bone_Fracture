{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # Paths\n",
    "    BASE_PATH = r'C:\\Final project 2\\backend\\datasets\\Combined_Set_Cls'\n",
    "    TRAIN_FRACTURE_PATH = os.path.join(BASE_PATH, 'train', 'Fracture')\n",
    "    TRAIN_HEALTHY_PATH = os.path.join(BASE_PATH, 'train', 'Healthy')\n",
    "    TEST_FRACTURE_PATH = os.path.join(BASE_PATH, 'test', 'Fracture')\n",
    "    TEST_HEALTHY_PATH = os.path.join(BASE_PATH, 'test', 'Healthy')\n",
    "    \n",
    "    # Model configuration\n",
    "    IMAGE_SIZE = 224\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_EPOCHS = 50\n",
    "    LEARNING_RATE = 0.0001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    NUM_CLASSES = 2\n",
    "    \n",
    "    # Training settings\n",
    "    PATIENCE = 10  # Early stopping patience\n",
    "    MODEL_SAVE_PATH = 'best_bone_fracture_model.pth'\n",
    "    \n",
    "    # Device configuration\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"Using device: {config.DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"WARNING: GPU not available, training will be slow!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoneFractureDataset(Dataset):\n",
    "    #create new dataset for classifier model training\n",
    "    \n",
    "    def __init__(self, fracture_path, healthy_path, transform=None):\n",
    "      \n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load fracture images (label = 1)\n",
    "        if os.path.exists(fracture_path):\n",
    "            fracture_files = [f for f in os.listdir(fracture_path) \n",
    "                            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "            for img_file in fracture_files:\n",
    "                self.images.append(os.path.join(fracture_path, img_file))\n",
    "                self.labels.append(1)\n",
    "        \n",
    "        # Load healthy images (label = 0)\n",
    "        if os.path.exists(healthy_path):\n",
    "            healthy_files = [f for f in os.listdir(healthy_path) \n",
    "                           if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "            for img_file in healthy_files:\n",
    "                self.images.append(os.path.join(healthy_path, img_file))\n",
    "                self.labels.append(0)\n",
    "        \n",
    "        print(f\"Loaded {len(self.images)} images:\")\n",
    "        print(f\"  - Fracture: {sum(self.labels)}\")\n",
    "        print(f\"  - Healthy: {len(self.labels) - sum(self.labels)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# No augmentation for testing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Data transforms created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"\\nCreating Training Dataset...\")\n",
    "train_dataset = BoneFractureDataset(\n",
    "    fracture_path=config.TRAIN_FRACTURE_PATH,\n",
    "    healthy_path=config.TRAIN_HEALTHY_PATH,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Test Dataset...\")\n",
    "test_dataset = BoneFractureDataset(\n",
    "    fracture_path=config.TEST_FRACTURE_PATH,\n",
    "    healthy_path=config.TEST_HEALTHY_PATH,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Set to 0 for Windows to avoid multiprocessing issues\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Set to 0 for Windows to avoid multiprocessing issues\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"  - Training batches: {len(train_loader)}\")\n",
    "print(f\"  - Testing batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title):\n",
    "    \n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "print(\"Getting sample images...\")\n",
    "# Get a batch of training data\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Got batch with {len(images)} images\")\n",
    "\n",
    "# Plot sample images\n",
    "print(\"Creating visualization...\")\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "\n",
    "for idx in range(min(8, len(images))):\n",
    "    plt.subplot(2, 4, idx + 1)\n",
    "    imshow(images[idx], f\"{'Fracture' if labels[idx] == 1 else 'Healthy'}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png', dpi=100, bbox_inches='tight')  # Reduced DPI for speed\n",
    "plt.close()  # Close instead of show to avoid display issues\n",
    "print(\"✓ Sample images saved as 'sample_images.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoneFractureClassifier(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(BoneFractureClassifier, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Get the number of features from the last layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Initialize model\n",
    "model = BoneFractureClassifier(num_classes=config.NUM_CLASSES, pretrained=True)\n",
    "model = model.to(config.DEVICE)\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.LEARNING_RATE,\n",
    "    weight_decay=config.WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Learning rate scheduler (reduces LR when validation accuracy plateaus)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "print(\"Loss function, optimizer, and scheduler initialized!\")\n",
    "print(f\"Initial learning rate: {config.LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "   \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100 * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "   \n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc='Validation')\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100 * correct / total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "print(\"Training and validation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_acc = 0.0\n",
    "patience_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "print(f\"Starting Training on {config.DEVICE}\")\n",
    "\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{config.NUM_EPOCHS}\")\n",
    "    \n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, config.DEVICE\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, _, _ = validate(\n",
    "        model, test_loader, criterion, config.DEVICE\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "            'history': history\n",
    "        }, config.MODEL_SAVE_PATH)\n",
    "        print(f\"  ✓ New best model saved! (Accuracy: {best_acc:.2f}%)\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  Patience: {patience_counter}/{config.PATIENCE}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config.PATIENCE:\n",
    "        print(f\"\\n Early stopping triggered after {epoch + 1} epochs\")\n",
    "        break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Total Training Time: {total_time/60:.2f} minutes\")\n",
    "print(f\"Best Validation Accuracy: {best_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "ax1.plot(history['val_loss'], label='Validation Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "ax2.plot(history['val_acc'], label='Validation Accuracy', marker='s')\n",
    "ax2.axhline(y=90, color='r', linestyle='--', label='90% Target')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Training history plot saved as 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(config.MODEL_SAVE_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "print(f\"Best validation accuracy: {checkpoint['best_acc']:.2f}%\\n\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating on Test Set...\")\n",
    "test_loss, test_acc, test_preds, test_labels = validate(\n",
    "    model, test_loader, criterion, config.DEVICE\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"TEST SET RESULTS\")\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate detailed metrics\n",
    "precision = precision_score(test_labels, test_preds, average='binary')\n",
    "recall = recall_score(test_labels, test_preds, average='binary')\n",
    "f1 = f1_score(test_labels, test_preds, average='binary')\n",
    "\n",
    "print(\"\\nDetailed Classification Metrics:\")\n",
    "\n",
    "print(f\"Accuracy:  {test_acc:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_labels, \n",
    "    test_preds, \n",
    "    target_names=['Healthy', 'Fracture']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Healthy', 'Fracture'],\n",
    "            yticklabels=['Healthy', 'Fracture'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix', fontsize=16, pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "# Add percentage annotations\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        percentage = cm[i, j] / cm[i].sum() * 100\n",
    "        plt.text(j + 0.5, i + 0.7, f'({percentage:.1f}%)', \n",
    "                ha='center', va='center', fontsize=10, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\nPer-Class Performance:\")\n",
    "\n",
    "print(\"\\nHealthy (Class 0):\")\n",
    "print(f\"  True Negatives:  {tn:4d}\")\n",
    "print(f\"  False Positives: {fp:4d}\")\n",
    "print(f\"  Specificity:     {tn/(tn+fp)*100:.2f}%\")\n",
    "\n",
    "print(\"\\nFracture (Class 1):\")\n",
    "print(f\"  True Positives:  {tp:4d}\")\n",
    "print(f\"  False Negatives: {fn:4d}\")\n",
    "print(f\"  Sensitivity:     {tp/(tp+fn)*100:.2f}%\")\n",
    "\n",
    "\n",
    "# Calculate and display balanced accuracy\n",
    "balanced_acc = (tp/(tp+fn) + tn/(tn+fp)) / 2 * 100\n",
    "print(f\"\\nBalanced Accuracy: {balanced_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataloader, device, num_images=12):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    images_shown = 0\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            for idx in range(images.size(0)):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                \n",
    "                plt.subplot(3, 4, images_shown + 1)\n",
    "                img = images[idx].cpu()\n",
    "                imshow(img, '')\n",
    "                \n",
    "                true_label = 'Fracture' if labels[idx] == 1 else 'Healthy'\n",
    "                pred_label = 'Fracture' if predicted[idx] == 1 else 'Healthy'\n",
    "                \n",
    "                color = 'green' if labels[idx] == predicted[idx] else 'red'\n",
    "                plt.title(f'True: {true_label}\\nPred: {pred_label}', \n",
    "                         color=color, fontsize=12, fontweight='bold')\n",
    "                \n",
    "                images_shown += 1\n",
    "            \n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Prediction samples saved as 'prediction_samples.png'\")\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, test_loader, config.DEVICE, num_images=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "results_summary = {\n",
    "    'Model': 'ResNet50',\n",
    "    'Test Accuracy': f\"{test_acc:.2f}%\",\n",
    "    'Test Loss': f\"{test_loss:.4f}\",\n",
    "    'Precision': f\"{precision:.4f}\",\n",
    "    'Recall': f\"{recall:.4f}\",\n",
    "    'F1-Score': f\"{f1:.4f}\",\n",
    "    'True Positives': tp,\n",
    "    'True Negatives': tn,\n",
    "    'False Positives': fp,\n",
    "    'False Negatives': fn,\n",
    "    'Training Time (minutes)': f\"{total_time/60:.2f}\",\n",
    "    'Epochs Trained': len(history['train_loss']),\n",
    "    'Image Size': config.IMAGE_SIZE,\n",
    "    'Batch Size': config.BATCH_SIZE,\n",
    "    'Learning Rate': config.LEARNING_RATE\n",
    "}\n",
    "\n",
    "# Save to CSV\n",
    "results_df = pd.DataFrame([results_summary])\n",
    "results_df.to_csv('model_results_summary.csv', index=False)\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df.T)\n",
    "print(\"\\nResults saved to 'model_results_summary.csv'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fxdetector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
